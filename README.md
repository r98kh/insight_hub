# ğŸš€ Insight Hub - Job Scheduling System

[![Django](https://img.shields.io/badge/Django-4.2.25-green.svg)](https://djangoproject.com/)
[![Python](https://img.shields.io/badge/Python-3.11-blue.svg)](https://python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-blue.svg)](https://postgresql.org/)
[![Redis](https://img.shields.io/badge/Redis-7-red.svg)](https://redis.io/)
[![Celery](https://img.shields.io/badge/Celery-5.5.3-green.svg)](https://celeryproject.org/)
[![Docker](https://img.shields.io/badge/Docker-Compose-blue.svg)](https://docker.com/)

A powerful and scalable job scheduling system built with Django REST Framework, featuring dynamic task scheduling, real-time execution monitoring, and comprehensive API documentation.

## ğŸ“‹ Table of Contents

- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [API Documentation](#-api-documentation)
- [Configuration](#-configuration)
- [Development](#-development)
- [Deployment](#-deployment)
- [Contributing](#-contributing)
- [License](#-license)

## âœ¨ Features

### ğŸ”§ Core Functionality

- **Dynamic Job Scheduling**: Create and manage scheduled jobs with cron expressions
- **Task Management**: Predefined task functions for common operations
- **Real-time Execution**: Monitor job execution status and results
- **User Management**: JWT-based authentication and authorization
- **API Documentation**: Interactive Swagger/OpenAPI documentation

### ğŸ“Š Advanced Features

- **Performance Optimization**: Database indexing and query optimization
- **Caching**: Redis-based caching for improved performance
- **Background Processing**: Celery-based asynchronous task execution
- **Clean Architecture**: Service layer and repository pattern implementation
- **Error Handling**: Comprehensive exception handling and logging

### ğŸ› ï¸ Built-in Task Functions

- **Email Tasks**: Send emails with customizable templates
- **Excel Processing**: Process Excel files with tax calculations
- **File Cleanup**: Automated cleanup of temporary files
- **Database Backup**: Automated database backup functionality

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Django API    â”‚    â”‚   Celery Beat   â”‚    â”‚  Celery Worker  â”‚
â”‚   (Port 8000)   â”‚    â”‚   (Scheduler)   â”‚    â”‚   (Executor)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Redis       â”‚
                    â”‚   (Message      â”‚
                    â”‚    Broker)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   PostgreSQL    â”‚
                    â”‚   (Database)    â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“ Project Structure

```
src/
â”œâ”€â”€ accounts/                 # User management
â”‚   â”œâ”€â”€ models.py           # Custom User model
â”‚   â”œâ”€â”€ services/           # User business logic
â”‚   â””â”€â”€ api/               # User API endpoints
â”œâ”€â”€ tasks/                  # Task definitions
â”‚   â”œâ”€â”€ models.py          # TaskDefinition & TaskParameter
â”‚   â”œâ”€â”€ task_functions.py  # Predefined task functions
â”‚   â”œâ”€â”€ services/          # Task business logic
â”‚   â””â”€â”€ repositories/     # Data access layer
â”œâ”€â”€ scheduler/              # Job scheduling
â”‚   â”œâ”€â”€ models.py          # ScheduledJob & JobExecutionLog
â”‚   â”œâ”€â”€ services/          # Scheduling business logic
â”‚   â”œâ”€â”€ repositories/      # Data access layer
â”‚   â””â”€â”€ tasks.py           # Celery tasks
â”œâ”€â”€ core/                  # Shared utilities
â”‚   â”œâ”€â”€ exceptions.py     # Custom exceptions
â”‚   â”œâ”€â”€ permissions.py    # Permission classes
â”‚   â”œâ”€â”€ pagination.py     # Pagination classes
â”‚   â””â”€â”€ mixins.py         # Reusable mixins
â””â”€â”€ insight_hub/          # Django project settings
    â”œâ”€â”€ settings.py       # Configuration
    â”œâ”€â”€ urls.py          # URL routing
    â””â”€â”€ celery.py        # Celery configuration
```

## ğŸš€ Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.11+ (for local development)
- PostgreSQL 15+
- Redis 7+

### 1. Clone the Repository

```bash
git clone https://github.com/r98kh/insight_hub.git
cd insight-hub
```

### 2. Environment Setup

Create a `.env` file in the project root:

```bash
# Database Configuration
POSTGRES_USER=insight_hub_user
POSTGRES_PASSWORD=insight_hub_password
POSTGRES_DB=insight_hub

# Django Configuration
SECRET_KEY=your-secret-key-here
DEBUG=True
ALLOWED_HOSTS=localhost,127.0.0.1,0.0.0.0

# Database Settings
DB_ENGINE=django.db.backends.postgresql
DB_NAME=insight_hub
DB_USER=insight_hub_user
DB_PASSWORD=insight_hub_password
DB_HOST=postgres
DB_PORT=5432

# Celery Configuration
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0
CACHE_LOCATION=redis://redis:6379/1
```

### 3. Start the Application

```bash
# Start all services
docker-compose up --build -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f backend
```

### 4. Access the Application

- **API Documentation**: http://localhost:8000/api/docs/
- **ReDoc Documentation**: http://localhost:8000/api/redoc/

### 5. Create Superuser

```bash
docker-compose exec backend python manage.py createsuperuser
```

### 6. Populate Task Definitions

```bash
docker-compose exec backend python manage.py populate_tasks
```

## ğŸ“š API Documentation

### Authentication

All API endpoints require authentication. Use JWT tokens:

```bash
# Login to get token
curl -X POST http://localhost:8000/api/auth/login/ \
  -H "Content-Type: application/json" \
  -d '{"username": "your_username", "password": "your_password"}'

# Use token in requests
curl -H "Authorization: Bearer <your_token>" \
  http://localhost:8000/api/scheduler/jobs/
```

### Key Endpoints

#### Jobs Management

- `GET /api/scheduler/jobs/` - List scheduled jobs
- `POST /api/scheduler/jobs/` - Create new job
- `GET /api/scheduler/jobs/{id}/` - Get job details
- `PUT /api/scheduler/jobs/{id}/` - Update job
- `DELETE /api/scheduler/jobs/{id}/` - Delete job

#### Task Definitions

- `GET /api/tasks/definitions/` - List available tasks
- `GET /api/tasks/definitions/{id}/` - Get task details

#### Job Execution

- `POST /api/scheduler/jobs/{id}/execute/` - Execute job immediately
- `POST /api/scheduler/jobs/{id}/pause/` - Pause job
- `POST /api/scheduler/jobs/{id}/resume/` - Resume job

### Example: Create a Scheduled Job

```bash
curl -X POST http://localhost:8000/api/scheduler/jobs/ \
  -H "Authorization: Bearer <your_token>" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Daily Email Report",
    "description": "Send daily email report",
    "task_definition": 1,
    "cron_expression": "0 9 * * *",
    "parameters": {
      "recipient_email": "admin@example.com",
      "subject": "Daily Report",
      "message": "Here is your daily report."
    }
  }'
```

## âš™ï¸ Configuration

### Environment Variables

| Variable            | Description       | Default                |
| ------------------- | ----------------- | ---------------------- |
| `SECRET_KEY`        | Django secret key | Required               |
| `DEBUG`             | Debug mode        | `False`                |
| `ALLOWED_HOSTS`     | Allowed hosts     | `localhost,127.0.0.1`  |
| `DB_HOST`           | Database host     | `postgres`             |
| `DB_PORT`           | Database port     | `5432`                 |
| `DB_NAME`           | Database name     | `insight_hub`          |
| `DB_USER`           | Database user     | `insight_hub_user`     |
| `DB_PASSWORD`       | Database password | Required               |
| `CELERY_BROKER_URL` | Celery broker URL | `redis://redis:6379/0` |
| `CACHE_LOCATION`    | Cache location    | `redis://redis:6379/1` |

### Celery Configuration

The system uses Celery for background task processing:

- **Worker Concurrency**: 4 processes
- **Task Routing**: Automatic routing based on task type
- **Rate Limiting**: Configurable per task type
- **Retry Policy**: Exponential backoff with max retries

### Database Optimization

Performance optimizations include:

- **Indexes**: Strategic database indexes for common queries
- **Query Optimization**: `select_related` and `prefetch_related` usage
- **Caching**: Redis-based caching for frequently accessed data
- **Pagination**: Efficient pagination for large datasets

## ğŸ› ï¸ Development

### Local Development Setup

1. **Install Dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

2. **Setup Database**:

   ```bash
   python manage.py migrate
   python manage.py populate_tasks
   ```

3. **Start Services**:

   ```bash
   # Terminal 1: Django server
   python manage.py runserver

   # Terminal 2: Celery worker
   celery -A insight_hub worker --loglevel=info

   # Terminal 3: Celery beat
   celery -A insight_hub beat --loglevel=info
   ```

### Code Quality

The project follows clean code principles:

- **Service Layer**: Business logic separated from views
- **Repository Pattern**: Data access abstraction
- **Custom Exceptions**: Meaningful error handling
- **Type Hints**: Python type annotations
- **Documentation**: Comprehensive docstrings

## ğŸš€ Deployment

### Production Deployment

1. **Environment Setup**:

   ```bash
   # Set production environment variables
   export DEBUG=False
   export SECRET_KEY=your-production-secret-key
   export ALLOWED_HOSTS=your-domain.com
   ```

2. **Database Migration**:

   ```bash
   docker-compose exec backend python manage.py migrate
   ```

3. **Static Files**:

   ```bash
   docker-compose exec backend python manage.py collectstatic --noinput
   ```

4. **Create Superuser**:
   ```bash
   docker-compose exec backend python manage.py createsuperuser
   ```

### Docker Production

```bash
# Build production images
docker-compose -f docker-compose.prod.yml build

# Start production services
docker-compose -f docker-compose.prod.yml up -d
```

### Monitoring

- **Health Checks**: Built-in health check endpoints
- **Logging**: Comprehensive logging configuration
- **Metrics**: Performance monitoring capabilities
- **Error Tracking**: Centralized error handling

## ğŸ“Š Performance

### Benchmarks

- **API Response Time**: < 100ms average
- **Job Execution**: < 1s for most tasks
- **Concurrent Users**: 100+ simultaneous users
- **Database Queries**: Optimized with < 5 queries per request

### Scaling

- **Horizontal Scaling**: Multiple Celery workers
- **Database Scaling**: Read replicas support
- **Caching**: Multi-level caching strategy
- **Load Balancing**: Nginx configuration included

## ğŸ¤ Contributing

We welcome contributions! Please follow these steps:

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Commit changes**: `git commit -m 'Add amazing feature'`
4. **Push to branch**: `git push origin feature/amazing-feature`
5. **Open a Pull Request**

### Development Guidelines

- Follow PEP 8 style guidelines
- Write comprehensive tests
- Update documentation
- Use meaningful commit messages
- Ensure all tests pass

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

### Getting Help

- **Documentation**: Check the API documentation at `/api/swagger/`
- **Issues**: Report bugs via GitHub Issues
- **Discussions**: Join our community discussions
- **Email**: Contact us at rasool.khorshidi1998@gmail.com

### Common Issues

1. **Database Connection**: Ensure PostgreSQL is running and accessible
2. **Redis Connection**: Verify Redis is running on the correct port
3. **Celery Tasks**: Check Celery worker logs for task execution issues
4. **Authentication**: Ensure JWT tokens are properly formatted

## ğŸ¯ Roadmap

### Upcoming Features

- [ ] **WebSocket Support**: Real-time job execution updates
- [ ] **Job Templates**: Reusable job configurations
- [ ] **Advanced Monitoring**: Detailed performance metrics
- [ ] **Multi-tenancy**: Support for multiple organizations
- [ ] **API Rate Limiting**: Advanced rate limiting strategies
- [ ] **Job Dependencies**: Complex job dependency chains

### Version History

- **v1.0.0**: Initial release with core functionality
- **v1.1.0**: Added performance optimizations

---

**Built with â¤ï¸ by Rasool Khorshidi**
